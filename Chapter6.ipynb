{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"Chapter6.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZAQi4ArS5xeI","colab_type":"text"},"source":["# 6 Pandasを使ったデータ加工処理"]},{"cell_type":"markdown","metadata":{"id":"dQCu_Uj25xeK","colab_type":"text"},"source":["6章では、2章で基礎を学んだPandasについて、さらに詳しく学んでいきます。Pandasは2章で学んだように、ある条件を満たすデータを抽出したり、操作するなど、さまざまな機能があります。さらに、特定の軸で集計したり、データ同士をつなげたり、欠けているデータを補ったり、時系列データを一括計算したり、複雑な処理も柔軟に行うことができます。Pandasは後半の章や、機械学習のモデルを適応させる前のいわゆる前処理でもよく使うことになりますので、この章はしっかりと学習してください。\n","\n","\n","ゴール：Pandasを使ったデータの抽出、操作、処理方法の知識を深める"]},{"cell_type":"markdown","metadata":{"id":"LYlNhUnC5xeL","colab_type":"text"},"source":["- **[6.1 概要と事前準備](#6.1-概要と事前準備)**\n","    - [6.1.1 この章で使うライブラリのインポート](#6.1.1-この章で使うライブラリのインポート)\n","<br><br>\n","- **[6.2 Pandasの基本的なデータ操作](#6.2-Pandasの基本的なデータ操作)**\n","    - [6.2.1 階層型インデックス](#6.2.1-階層型インデックス)\n","    - [6.2.2 データの結合](#6.2.2-データの結合)\n","    - [6.2.3 データの操作と変換](#6.2.3-データの操作と変換)\n","    - [6.2.4 データの集約とグループ演算](#6.2.4-データの集約とグループ演算)\n","<br><br>\n","- **[6.3 欠損データと異常値の取り扱いの基礎](#6.3-欠損データと異常値の取り扱いの基礎)**\n","    - [6.3.1 欠損データの扱い方](#6.3.1-欠損データの扱い方)\n","    - [6.3.2 異常データの扱い方](#6.3.2-異常データの扱い方)\n","<br><br>\n","- **[6.4 時系列データの取り扱いの基礎](#6.4-時系列データの取り扱いの基礎)**\n","    - [6.4.1 時系列データの処理と変換](#6.4.1-時系列データの処理と変換)\n","    - [6.4.2 移動平均](#6.4.2-移動平均)\n","<br><br>\n","- **[6.5 総合問題](#6.5-総合問題)**\n","    - [■総合問題6-1 データ操作](#■総合問題6-1-データ操作)"]},{"cell_type":"markdown","metadata":{"id":"Az77nUIr5xeM","colab_type":"text"},"source":["***"]},{"cell_type":"markdown","metadata":{"id":"rK7NvXRs5xeN","colab_type":"text"},"source":["## 6.1 概要と事前準備\n","\n","キーワード：Numpy、Scipy、Pandas\n","\n","この章ではPandasを使ったデータ加工処理について、もう少し詳しく学んでいきます。Pandasは2章で学んだように、ある条件を満たすデータを抽出したり、操作したりするなど、さまざまな機能があります。\n","\n","たとえば、全国の小学校で同じ算数のテストを実施したケースを考えてみます。\n","それぞれの都道府県の最高点取得者だけを抜き出したいこともあるでしょうし、それぞれの都道府県の平均点を出したいこともあるでしょう。このように、さまざまな集計軸があります。さらに、都道府県×学校×クラスの3軸で平均値を算出したい場合や、さらに男女で計算したい場合など、軸が複数になっているケースもあります。Pandasを使えば、そのような集計をすることもできます。また、他のデータ（たとえば、国語の試験結果）とつなげたいときも、キー（各学生に与えられた一意となるデータなど）があれば、結合して1つの`DataFrame`オブジェクトにして、まとめて処理できます。\n","\n","そのほか、時系列データを扱うときもPandasは役に立ちます。\n","たとえば、ある店舗の日時の売上推移データを取り扱うときに、1週間や1か月ごとの平均値の推移を簡単に計算することができます。これらのプログラムをいちから記述するとなると大変ですが、Pandasではこのような計算も1～2行ほどのコードを書くだけで実行できます。さらに、データに欠損値や何か異常値が入っているとき、それらを何らかの方法で一括処理したい場合にも使えます。\n","\n","もちろん、これらの処理は自分で、いちからPythonのプログラムを書くことで対応できますが、実装するのに時間がかかります。それに比べてPandasの機能を使えば、簡単に操作できます。また、 機械学習のモデルを構築するときは、そのアルゴリズムが使えるようにデータを前処理する必要があります。たとえば、縦に並んでいたデータのカラムを横に並べたい場面などもあり、そういった操作もPandasなら簡単にできます。\n","\n","上記のようなデータ操作をする場合、SQLやエクセルのピボットテーブルなどを使っても処理できますが、Pythonのプログラムだけで一貫してコーディングしたい場合はPandasを使うと便利です。\n","なおPandasには、グラフの描画機能もあり、ハンドリングしたデータをグラフとしてすぐに描画できます。データのグラフ化については7章でみていくことにします。"]},{"cell_type":"markdown","metadata":{"id":"cPUsm9EJ5xeO","colab_type":"text"},"source":["### 6.1.1 この章で使うライブラリのインポート\n","\n","この章では、2章で紹介した各種ライブラリを使います。次のようにインポートしていることを前提として、以下、進めていきます。"]},{"cell_type":"code","metadata":{"id":"9r_zV6EH5xeP","colab_type":"code","colab":{}},"source":["# 以下のライブラリを使うので、あらかじめ読み込んでおいてください\n","import numpy as np\n","import numpy.random as random\n","import scipy as sp\n","import pandas as pd\n","from pandas import Series, DataFrame\n","\n","# 可視化ライブラリ\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import seaborn as sns\n","%matplotlib inline\n","\n","# 小数第3位まで表示\n","%precision 3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u8phy9uG5xeT","colab_type":"text"},"source":["## 6.2 Pandasの基本的なデータ操作\n","ゴール：Pandasの階層型インデックスを使える、データの結合ができる、groupbyメソッドなどを使って集計処理ができる\n","\n","まずは、Pandasの基本的なデータ操作から始めます。"]},{"cell_type":"markdown","metadata":{"id":"FSJHGfAe5xeV","colab_type":"text"},"source":["### 6.2.1 階層型インデックス\n","キーワード：階層型インデックス\n"]},{"cell_type":"markdown","metadata":{"id":"2UP9Qa2n5xeW","colab_type":"text"},"source":["データを複数軸で集計したいとき、設定すると便利なのが**階層型インデックス**です。\n","2章でPandasのインデックスについて少し扱いましたが、インデックスとは索引やラベルのようなイメージです。2章では、1つのインデックスだけを扱いましたが、この章の冒頭で説明したように、複数の軸で階層的にインデックスを設定したいこともあります。階層的にインデックスを設定することで、各階層ごとに集計が可能になり、便利です。\n","\n","次に示すデータセットは、インデックスを2段構造で設定した例です。インデックスを設定するには、`index`パラメータにその値を指定します。この例では、1階層目のインデックスとして`a`と`b`、2階層目のインデックスとして`1`と`2`を設定しています。\n","\n","また、列の側につけるカラムとして、1階層目に`Osaka`、`Tokyo`、`Osaka`、2階層目に`Blue`、`Red`、`Red`を設定しています。\n"]},{"cell_type":"code","metadata":{"id":"QiqREzJw5xeX","colab_type":"code","colab":{}},"source":["# 3列3行のデータを作成し、インデックスとカラムを設定\n","hier_df= DataFrame(\n","    np.arange(9).reshape((3,3)),\n","    index = [\n","        ['a','a','b'],\n","        [1,2,2]\n","    ], \n","    columns = [\n","        ['Osaka','Tokyo','Osaka'],\n","        ['Blue','Red','Red']\n","    ]\n",")\n","hier_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"42ZiVYdY5xeb","colab_type":"text"},"source":["これらのインデックスやカラムには、名前をつけることもできます。"]},{"cell_type":"code","metadata":{"id":"sVdsaXN65xec","colab_type":"code","colab":{}},"source":["# indexに名前を付ける\n","hier_df.index.names =['key1','key2']\n","# カラムに名前を付ける\n","hier_df.columns.names =['city','color']\n","hier_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rx5dS3wG5xeg","colab_type":"text"},"source":["#### カラムの絞り込み\n","\n","ここでたとえば、カラムの`city`が`Osaka`のデータだけを見たいとしましょう。次のようにすると、グループの絞り込みができます。"]},{"cell_type":"code","metadata":{"id":"EIrwRqqb5xei","colab_type":"code","colab":{}},"source":["hier_df['Osaka']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wDUCwPL25xek","colab_type":"text"},"source":["#### インデックスを軸にした集計\n","\n","次はインデックスを軸にした集計の例です。以下の例は、`key2`を軸に合計を計算する例です。"]},{"cell_type":"code","metadata":{"id":"pb-_Mx-s5xel","colab_type":"code","colab":{}},"source":["# 階層ごとの要約統計量：行合計\n","hier_df.sum(level = 'key2', axis = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9VctanIM5xeo","colab_type":"text"},"source":["同様にして、`color`を軸に合計を計算する場合は、次のようにします。列方向に合計する場合は、`axis`パラメータを1に設定します。"]},{"cell_type":"code","metadata":{"id":"hL9OX-g45xep","colab_type":"code","colab":{}},"source":["# 列合計\n","hier_df.sum(level = 'color', axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"azr0hMjY5xes","colab_type":"text"},"source":["#### インデックスの要素の削除\n","\n","あるインデックスを削除したい場合は、`drop`メソッドを使います。`drop`メソッドを使うと、インデックスの要素を削除できます。次の例では、`key1`の`b`を削除しています。"]},{"cell_type":"code","metadata":{"id":"VdnWIz_N5xet","colab_type":"code","colab":{}},"source":["hier_df.drop(['b'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6tQZfwl5xev","colab_type":"text"},"source":["#### <練習問題 6-1>\n","\n","次のデータに対して、`Kyoto`の列だけ抜き出してみましょう。"]},{"cell_type":"code","metadata":{"id":"XMteyjxz5xew","colab_type":"code","colab":{}},"source":["hier_df1 = DataFrame(\n","    np.arange(12).reshape((3,4)),\n","    index = [['c','d','d'],[1,2,1]],\n","    columns = [\n","        ['Kyoto','Nagoya','Hokkaido','Kyoto'],\n","        ['Yellow','Yellow','Red','Blue']\n","    ]\n",")\n","\n","hier_df1.index.names = ['key1','key2']\n","hier_df1.columns.names = ['city','color']\n","hier_df1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jlRg6HYm5xez","colab_type":"text"},"source":["#### <練習問題 6-2>\n","\n","<練習問題 6-1>のデータに対して、`city`をまとめて列同士の平均値を出してください。"]},{"cell_type":"markdown","metadata":{"id":"OoYU1xy15xe0","colab_type":"text"},"source":["#### <練習問題 6-3>\n","\n","<練習問題 6-1>のデータに対して、`key2`ごとに行の合計値を算出してみましょう。\n"]},{"cell_type":"markdown","metadata":{"id":"9YhNkZTT5xe1","colab_type":"text"},"source":["### 6.2.2 データの結合\n","キーワード：内部結合、外部結合、縦結合"]},{"cell_type":"markdown","metadata":{"id":"47nLmBEm5xe3","colab_type":"text"},"source":["データの結合については2章で少し学びました。データを結合したいケースは多々あり、データをつなげることで集計がしやすくなったり、新しい軸における値がわかったりします。ぜひ、マスターしてください。\n","ただし、結合と言っても、さまざまなパターンがあります。以下でそれらを紹介していきます。\n","\n","まずは、この節でサンプルとして使う結合の対象となるデータを準備します。ここでは次に提示する`data1`（以下、データ1）と`data2`（以下、データ2）の2つのデータを使います。"]},{"cell_type":"code","metadata":{"id":"NZMvSotI5xe4","colab_type":"code","colab":{}},"source":["# データ1の準備\n","data1 = {\n","    'id': ['100', '101', '102', '103', '104', '106', '108', '110', '111',' 113'],\n","    'city': ['Tokyo', 'Osaka', 'Kyoto', 'Hokkaido', 'Tokyo', 'Tokyo', 'Osaka', 'Kyoto', 'Hokkaido', 'Tokyo'],\n","    'birth_year': [1990, 1989, 1992, 1997, 1982, 1991, 1988, 1990, 1995, 1981],\n","    'name': ['Hiroshi', 'Akiko', 'Yuki', 'Satoru', 'Steeve', 'Mituru', 'Aoi', 'Tarou', 'Suguru','Mitsuo']\n","}\n","df1 = DataFrame(data1)\n","df1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3dljlvdP5xe8","colab_type":"code","colab":{}},"source":["# データ2の準備\n","data2 = {\n","    'id': ['100', '101', '102', '105', '107'],\n","    'math': [50, 43, 33, 76, 98],\n","    'english': [90, 30, 20, 50, 30],\n","    'sex': ['M','F','F','M','M'], \n","    'index_num': [0, 1, 2, 3, 4]\n","}\n","df2 = DataFrame(data2)\n","df2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r3ofGA7Y5xe-","colab_type":"text"},"source":["### 結合\n","\n","では、この2つのデータを結合する方法を見ていきましょう。\n","データ1とデータ2を結合する方法は、次の4パターンが考えられます。\n","\n","①内部結合（INNER JOIN）\n","両方にキーがあるときに結合します。\n","\n","②全結合（FULL JOIN）\n","どちらかにキーがあるときに結合します。\n","\n","③左外部結合（LEFT JOIN）\n","左側にあるデータのキーがある時に結合します。\n","\n","④右外部結合（RIGHT JOIN）\n","右側にあるデータのキーがある時に結合します。\n","\n","ここでは主に、「内部結合」と「（左）外部結合」を使います。この2つを理解しておいてください。"]},{"cell_type":"markdown","metadata":{"id":"bkArjKTt5xe_","colab_type":"text"},"source":["（※図は書籍を参照してください※）"]},{"cell_type":"markdown","metadata":{"id":"7hFJ-dvr5xfA","colab_type":"text"},"source":["#### 内部結合\n","mergeメソッドの結合方法のデフォルトは内部結合です。上記のデータ2つに対して、`id`をキーとして内部結合すると、以下のようになります。`on`パラメータでキーを指定します。"]},{"cell_type":"code","metadata":{"id":"WW-Kcy3A5xfB","colab_type":"code","colab":{}},"source":["# データのマージ（内部結合。キーは自動的に認識されるが、onで明示的に指定可能）\n","print('・結合テーブル')\n","pd.merge(df1, df2, on = 'id')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-UuTG3AU5xfD","colab_type":"text"},"source":["`id`の値が両方の`Dataframe`オブジェクトに存在するものみが表示されました。"]},{"cell_type":"markdown","metadata":{"id":"UaGDBLXI5xfE","colab_type":"text"},"source":["#### 全結合\n","次の例は、どちらのデータにも存在するデータで結合しています。これが全結合です。全結合では`how`パラメータに`outer`を指定します。結合する値がない場合は、`NaN`になります。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"HOo2FzXX5xfF","colab_type":"code","colab":{}},"source":["# データのマージ（全結合）\n","pd.merge(df1, df2, how = 'outer')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"clM-p4NE5xfI","colab_type":"text"},"source":["なお、`left_index`パラメータや`right_on`パラメータを使うと、キーをインデックスで指定して結合できます。次の例は、左側のデータのインデックスと、右側のデータのindex_numカラムをキーとして指定するものです。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"TG4mG5VN5xfJ","colab_type":"code","colab":{}},"source":["# index によるマージ\n","pd.merge(df1, df2, left_index = True, right_on = 'index_num')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAyQUPQS5xfN","colab_type":"text"},"source":["#### 左外部結合\n","左外部結合は`how`パラメータに`left`を指定します。次の例は、左側のテーブル（ひとつめの引数）に合わせて、`Dataframe`オブジェクトのデータを結合するものです。左側に対応するデータが右（ふたつめの引数）にない場合は、`NaN`になります。"]},{"cell_type":"code","metadata":{"id":"nATBKic-5xfS","colab_type":"code","colab":{}},"source":["# データのマージ（left）\n","pd.merge(df1, df2, how = 'left')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0q1CXK6l5xfY","colab_type":"text"},"source":["#### 縦結合\n","\n","これまでは、何らかのキーに紐付いてデータをマージしていましたが、`concat`メソッドを使うと、データを縦方向に積み上げられます。これを縦結合と言います。"]},{"cell_type":"code","metadata":{"id":"7iQslzet5xfZ","colab_type":"code","colab":{}},"source":["# データ3の準備\n","data3 = {\n","    'id': ['117', '118', '119', '120', '125'],\n","    'city': ['Chiba', 'Kanagawa', 'Tokyo', 'Fukuoka', 'Okinawa'],\n","    'birth_year': [1990, 1989, 1992, 1997, 1982],\n","    'name': ['Suguru', 'Kouichi', 'Satochi', 'Yukie', 'Akari']\n","}\n","df3 = DataFrame(data3)\n","df3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7yIzvARC5xfc","colab_type":"code","colab":{}},"source":["# concat 縦結合\n","concat_data = pd.concat([df1,df3])\n","concat_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-cCUtyL5xfe","colab_type":"text"},"source":["#### <練習問題 6-4>\n","\n","下記の2つのデータテーブルに対して、内部結合してみましょう。"]},{"cell_type":"code","metadata":{"id":"bAlB2l7w5xff","colab_type":"code","colab":{}},"source":["# データ4の準備\n","data4 = {\n","    'id': ['0', '1', '2', '3', '4', '6', '8', '11', '12', '13'],\n","    'city': ['Tokyo', 'Osaka', 'Kyoto', 'Hokkaido', 'Tokyo', 'Tokyo', 'Osaka', 'Kyoto', 'Hokkaido', 'Tokyo'],\n","    'birth_year': [1990, 1989, 1992, 1997, 1982, 1991, 1988, 1990, 1995, 1981],\n","    'name': ['Hiroshi', 'Akiko', 'Yuki', 'Satoru', 'Steeve', 'Mituru', 'Aoi', 'Tarou', 'Suguru', 'Mitsuo']\n","}\n","df4 = DataFrame(data4)\n","df4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIOO-d_A5xfh","colab_type":"code","colab":{}},"source":["# データ5の準備\n","data5 = {\n","    'id': ['0', '1', '3', '6', '8'],\n","    'math' : [20, 30, 50, 70, 90],\n","    'english': [30, 50, 50, 70, 20],\n","    'sex': ['M', 'F', 'F', 'M', 'M'],\n","    'index_num': [0, 1, 2, 3, 4]\n","}\n","df5 = DataFrame(data5)\n","df5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x4i9lWkF5xfj","colab_type":"text"},"source":["#### <練習問題  6-5>\n","\n","<練習問題 6-4>のデータを使って、`df4`をベースに`df5`のテーブルを全結合してみましょう。"]},{"cell_type":"markdown","metadata":{"id":"8lkjS2nj5xfl","colab_type":"text"},"source":["#### <練習問題 6-6>\n","<練習問題 6-4>のデータを使って、`df4`に対して、以下のデータを縦結合してみましょう。"]},{"cell_type":"code","metadata":{"id":"1dAle1rm5xfl","colab_type":"code","colab":{}},"source":["# データの準備\n","data6 = {\n","    'id': ['70', '80', '90', '120', '150'],\n","    'city': ['Chiba', 'Kanagawa', 'Tokyo', 'Fukuoka', 'Okinawa'],\n","    'birth_year': [1980, 1999, 1995, 1994, 1994],\n","    'name': ['Suguru', 'Kouichi', 'Satochi', 'Yukie', 'Akari']\n","}\n","df6 = DataFrame(data6)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ktLgksJV5xfn","colab_type":"text"},"source":["### 6.2.3 データの操作と変換\n","キーワード：データのピボット操作、重複データ、マッピング、ビン分割"]},{"cell_type":"markdown","metadata":{"id":"dcL9aRy35xfo","colab_type":"text"},"source":["次に、データの操作と変換（ピボット操作、データの重複があった場合の処理、マッピング、ビン分割など）について扱っていきましょう。\n","\n","#### ピボット操作\n","まずは、データのピボット操作について学びます。ピボット操作とは、行を列に、列を行にする操作です。もう一度、これまで使ってきた階層テーブル`hier_df`を例に考えます。"]},{"cell_type":"code","metadata":{"id":"hlIc3GBF5xfp","colab_type":"code","colab":{}},"source":["# hier_dfを用意\n","hier_df= DataFrame(\n","    np.arange(9).reshape((3, 3)),\n","    index = [\n","        ['a', 'a', 'b'],\n","        [1, 2, 2]\n","    ],\n","    columns = [\n","        ['Osaka', 'Tokyo', 'Osaka'],\n","        ['Blue','Red','Red']\n","    ]\n",")\n","hier_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"R9K1eNaD5xfr","colab_type":"text"},"source":["次のように`stack`メソッドを実行すると、行と列が入れ替わった`DataFrame`オブジェクトを再構成できます。"]},{"cell_type":"code","metadata":{"id":"lMpHFcKy5xfr","colab_type":"code","colab":{}},"source":["#　ピボット操作で「Blue、Red」の列を行に変更\n","hier_df.stack()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V9b9uHf55xfv","colab_type":"text"},"source":["`unstack`メソッドを使うと、逆の操作が可能です。"]},{"cell_type":"code","metadata":{"id":"aBmvXOdi5xfw","colab_type":"code","colab":{}},"source":["# unstackメソッドで、「Blue、Red」の行を列に変更\n","hier_df.stack().unstack()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M8FRfYeM5xfy","colab_type":"text"},"source":["上記のデータ操作では、列にあったものを行に持ってきたり、行であったものを列に持ってきたりしています。これらのテクニックは、データのモデリング前の処理として使うことも多く便利ですので、ぜひ理解して使えるようしてください。"]},{"cell_type":"markdown","metadata":{"id":"0e1IIXjX5xfy","colab_type":"text"},"source":["#### 重複データの除去\n","次は、重複があるデータの処理です。データ分析をしていると、データに重複があることもありますし、自分で実際に集計等していて重複が混じることもあり、そのチェックをするという意味で重要です。\n","\n","まず例として、重複があるデータを準備します。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"jV2fi1F-5xfz","colab_type":"code","colab":{}},"source":["#　重複があるデータ\n","dupli_data = DataFrame({\n","        'col1': [1, 1, 2, 3, 4, 4, 6, 6],\n","        'col2': ['a', 'b', 'b', 'b', 'c', 'c', 'b', 'b']\n","})\n","print('・元のデータ')\n","dupli_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wLicl8tX5xf0","colab_type":"text"},"source":["重複の判定には`duplicated`メソッドを使います。それぞれの行が確認され、重複があるときは、`True`となります。ただし、重複のあるデータでも1回目では`False`となり、2回目から`True`になります。"]},{"cell_type":"code","metadata":{"id":"kyc_4vzJ5xf1","colab_type":"code","colab":{}},"source":["#　重複判定\n","dupli_data.duplicated()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PvY7z4t_5xf2","colab_type":"text"},"source":["`drop_duplicates`メソッドを使うと、重複したデータを削除した結果のデータが返されます。"]},{"cell_type":"code","metadata":{"id":"WEsDWXmN5xf2","colab_type":"code","colab":{}},"source":["#　重複削除\n","dupli_data.drop_duplicates()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CJU6xgaX5xf4","colab_type":"text"},"source":["#### マッピング処理\n","次に、マッピング処理を説明します。これは、Excelのvlookup関数のような処理です。共通のキーとなるデータに対して、一方の（参照）テーブルからそのキーに対応するデータを引っ張ってくる機能です。以下は、都道府県名と地域名を対応付けた参照データです。\n","\n","Tokyo（東京）→Kanto（関東）\n","\n","Hokkaido（北海道）→Hokkaido（北海道）\n","\n","Osaka（大阪）→Kansai（関西）\n","\n","Kyoto（京都）→Kansai（関西）\n"]},{"cell_type":"markdown","metadata":{"id":"xXdFSbjo5xf5","colab_type":"text"},"source":["まず次のように参照データを作ります。"]},{"cell_type":"code","metadata":{"id":"cLXMsKa-5xf6","colab_type":"code","colab":{}},"source":["# 参照データ\n","city_map ={\n","    'Tokyo': 'Kanto',\n","    'Hokkaido': 'Hokkaido',\n","    'Osaka': 'Kansai',\n","    'Kyoto':'Kansai'\n","}\n","city_map"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0EW8aD445xf7","colab_type":"text"},"source":["次の例は、`df1`の`city`カラムをベースとして、上の参照データ`city_map`から対応する地域名データを持ってきて、新しく一番右に`region`というカラムとして追加するものです。"]},{"cell_type":"code","metadata":{"id":"OE07lcBL5xf8","colab_type":"code","colab":{}},"source":["#　参照データを結合\n","# もし対応するデータがなかったら、NaNになる。\n","df1['region'] = df1['city'].map(city_map)\n","df1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LqXNM4UQ5xf-","colab_type":"text"},"source":["このように新しい`region`というカラムをつけることで、この単位で集計が可能になります。"]},{"cell_type":"markdown","metadata":{"id":"dy4EIMiJ5xf-","colab_type":"text"},"source":["##### 無名関数とmapを組み合わせる\n","\n","次は、1章で学んだ無名関数と`map`を使って、カラムの中の一部のデータを取り出す処理をする例です。具体的には、`birth_year`の上3桁を取得します。関数適応やループなどを使って要素を1つ1つ取り出して処理するより便利なので、まとめて処理したい場合は、このようなやり方を検討することをおすすめします。"]},{"cell_type":"code","metadata":{"id":"ZsvD-s4k5xf-","colab_type":"code","colab":{}},"source":["#　birth_year の上3つの数字・文字を取り出す\n","df1['up_two_num'] = df1['birth_year'].map(lambda x: str(x)[0:3])\n","df1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DmANCrUp5xgA","colab_type":"text"},"source":["#### ビン分割\n","\n","最後にビン分割について説明します。これは、ある離散的な範囲にデータを分割して集計したい場合に、便利な機能です。具体的には、上のデータの`birth_year`に対して、5年区切りで集計をしたい場合など、ある特定の分割をして計算をしたいときに使います。\n","\n","たとえば以下のように、1980、1985、1990、1995、2000のように5年単位でビン分割するためのリストを用意し、Pandasの`cut`関数を使うと、そのように分割できます。`cut`関数では、1つ目の引数に分割するデータ、2つ目の引数に分割する境界値を、それぞれ指定します。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"PXmCdaDM5xgA","colab_type":"code","colab":{}},"source":["#　分割の粒度\n","birth_year_bins = [1980, 1985, 1990, 1995, 2000]\n","\n","# ビン分割の実施\n","birth_year_cut_data = pd.cut(df1.birth_year, birth_year_bins)\n","birth_year_cut_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UtgqeVGY5xgD","colab_type":"text"},"source":["なお、上記のプログラムでは、「1980～1985」の区切りの中には1980は含まれませんが、1985は含まれています。つまり、指定した基準は、「～より後で、～以前」という区切り方として使われます。この動作は、cut関数に`left`オプションや`right`オプションを指定することで変更できます。"]},{"cell_type":"markdown","metadata":{"id":"YBQ11kVX5xgE","colab_type":"text"},"source":["上記の結果を使って、それぞれの数を集計したい場合は、`value_counts`関数を使います。"]},{"cell_type":"code","metadata":{"id":"hwysUgsc5xgH","colab_type":"code","colab":{}},"source":["# 集計結果\n","pd.value_counts(birth_year_cut_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-V7eOABg5xgK","colab_type":"text"},"source":["labelsパラメータを指定することで、それぞれのビンに名前をつけることもできます。"]},{"cell_type":"code","metadata":{"id":"ST7GCDJe5xgL","colab_type":"code","colab":{}},"source":["# 名前をつける\n","group_names = ['early1980s', 'late1980s', 'early1990s', 'late1990s']\n","birth_year_cut_data = pd.cut(df1.birth_year, birth_year_bins, labels = group_names)\n","pd.value_counts(birth_year_cut_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zI73U6iV5xgN","colab_type":"text"},"source":["上記では、ビン分割のリストを用意しましたが、あらかじめ分割数を指定したい場合は、以下のように設定できます。なお、データによってはきれいに割り切れず小数点以下がでてくるので注意しましょう。"]},{"cell_type":"code","metadata":{"id":"6IHD-rb95xgN","colab_type":"code","colab":{}},"source":["# 数字で分割数指定可能。ここでは2つに分割\n","pd.cut(df1.birth_year, 2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z8AXeaui5xgR","colab_type":"text"},"source":["また`qcut`関数を使うと、分位点での分割もできます。`qcut`関数を使うことで、ほぼ同じサイズのビンを作成することができます。"]},{"cell_type":"code","metadata":{"id":"51qrZ5225xgR","colab_type":"code","colab":{}},"source":["pd.value_counts(pd.qcut(df1.birth_year, 2))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cIhPbDTK5xgT","colab_type":"text"},"source":["ここでは対象としたデータが、1981、1982、1988、1989、1990、1990、1991、1992、1995、1997と、ちょうど中央値にあたる値が2つあるため、6つと4つで分割されました。"]},{"cell_type":"markdown","metadata":{"id":"NWZcbDiM5xgT","colab_type":"text"},"source":["このビン分割、はじめ何に使うのかイメージがわきにくいかもしれませんが、具体的には、顧客の購買金額合計を分けて、それぞれの顧客層（優良顧客など）を分析をしたい場合など、マーケティング分析にも使えます。次の7章の総合問題演習で扱っていくことにしましょう。"]},{"cell_type":"markdown","metadata":{"id":"Dpv7QGjh5xgU","colab_type":"text"},"source":["#### <練習問題 6-7>\n","\n","3章で使用した数学の成績を示すデータである「student-mat.csv」を読み込み、年齢（`age`）を2倍にしたカラムを末尾に追加してみましょう。"]},{"cell_type":"code","metadata":{"id":"LF3v-98f5xgU","colab_type":"code","colab":{}},"source":["# 3章で用意したデータがあるpathに移動して、以下を実行してください。例） cd pathの名前\n","student_data_math = pd.read_csv('student-mat.csv', sep=';')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i7-thh9a5xgX","colab_type":"text"},"source":["#### <練習問題 6-8>\n","\n","<練習問題 6-7>と同じデータで、「`absences`」のカラムについて、以下の3つのビンに分けてそれぞれの人数を数えてみましょう。なお、`cut`のデフォルトの挙動は右側が閉区間です。今回は、`cut`関数に対して`right=False`のオプションを指定して、右側を開区間としてください。"]},{"cell_type":"code","metadata":{"id":"-1EQlTKY5xgY","colab_type":"code","colab":{}},"source":["#　分割の粒度\n","absences_bins = [0,1,5,100]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OI6L1moP5xga","colab_type":"text"},"source":["#### <練習問題 6-9>\n","\n","上記と同じデータで、「`absences`」のカラムについて、`qcut`関数を用いて3つのビンに分けてみましょう。"]},{"cell_type":"markdown","metadata":{"id":"WYuqnCNU5xgb","colab_type":"text"},"source":["### 6.2.4 データの集約とグループ演算\n","キーワード：groupby"]},{"cell_type":"markdown","metadata":{"id":"jpsYTvdT5xgb","colab_type":"text"},"source":["ここでは、あるカラムを軸にして集計する処理を学びます。2章で少し扱いましたが、`groupby`メソッドを使うことで、ある変数を軸として、その単位で集計処理をします。以前使った`df1`データを対象に、集約やグループ演算をしたいと思います。"]},{"cell_type":"code","metadata":{"id":"qvlecQ7S5xgc","colab_type":"code","colab":{}},"source":["# データを用意（確認）、ただし、region付き\n","df1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"h9G_ljMV5xge","colab_type":"text"},"source":["以下のように`groupby`メソッドでグループ化してから`size`メソッドを使うと、それぞれの`city`の値がいくつかあるのかを計算できます。"]},{"cell_type":"code","metadata":{"id":"LAxc3Gvw5xgf","colab_type":"code","colab":{}},"source":["# サイズ情報\n","df1.groupby('city').size()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGC61NXX5xgg","colab_type":"text"},"source":["次は、`city`を軸として、`birth_year`の平均値を算出する例です。"]},{"cell_type":"code","metadata":{"id":"Hx7Am4om5xgg","colab_type":"code","colab":{}},"source":["# cityを軸に、birth_yearの平均値を求める\n","df1.groupby('city')['birth_year'].mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZYG-vRQ5xgj","colab_type":"text"},"source":["軸は複数設定することもできます。たとえば、`region`、`city`を2軸として、`birth_year`の平均値を求めると、次のようになります。"]},{"cell_type":"code","metadata":{"id":"gZoRGRxz5xgj","colab_type":"code","colab":{}},"source":["df1.groupby(['region', 'city'])['birth_year'].mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MTkWlsIo5xgk","colab_type":"text"},"source":["なお、`groupby`メソッドに`as_index = False`パラメータを設定すると、インデックスが設定されなくなります。そのままテーブルとして扱いたいときに便利です。"]},{"cell_type":"code","metadata":{"id":"V0tLbwXy5xgl","colab_type":"code","colab":{}},"source":["df1.groupby(['region', 'city'], as_index = False)['birth_year'].mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2a5hfGOe5xgm","colab_type":"text"},"source":["他にも`groupby`メソッドには、イテレータという、反復的に値を取り出す機能があり、次のように、結果の要素をPythonの`for`などでループ処理できて便利です。"]},{"cell_type":"markdown","metadata":{"id":"bVXM9jDk5xgm","colab_type":"text"},"source":["以下の例は、groupはregionの名前取り出し、subdfはそのregionのみの行をすべて抽出するというものです。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"06wIxe8x5xgn","colab_type":"code","colab":{}},"source":["for group, subdf in df1.groupby('region'):\n","    print('==========================================================')\n","    print('Region Name:{0}'.format(group))\n","    print(subdf)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Atrpe4e5xgo","colab_type":"text"},"source":["データに対して、複数の計算をまとめて行いたいときには、`agg`メソッドを使うと便利です。`agg`メソッドの引数には、実行したい関数名のリストを渡します。以下は、カウント、平均、最大、最小を計算する例です。"]},{"cell_type":"markdown","metadata":{"id":"7o9CK1GL5xgo","colab_type":"text"},"source":["なお、以下の例では、対象データとして3章で扱ったstudent-mat.csvを使って計算しています。このデータがあるファイルディレクトリに移動して、データを読み込んで実行してください。"]},{"cell_type":"code","metadata":{"id":"X4VZ3WJF5xgp","colab_type":"code","colab":{}},"source":["# 3章で用意したデータがあるpathに移動して、以下を実行してください。例） cd pathの名前\n","student_data_math = pd.read_csv('student-mat.csv', sep = ';')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5ACqa7x5xgq","colab_type":"code","colab":{}},"source":["# 列に複数の関数を適応\n","functions = ['count','mean','max','min']\n","grouped_student_math_data1 = student_data_math.groupby(['sex','address'])\n","grouped_student_math_data1['age','G1'].agg(functions)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UNs4RVoX5xgw","colab_type":"text"},"source":["#### <練習問題 6-10>\n","\n","<練習問題 6-7>で使用した「student-mat.csv」を使って、Pandasの集計処理をしてみましょう。まずは、学校（`school`）を軸にして、`G1`の平均点をそれぞれ求めてみましょう。"]},{"cell_type":"markdown","metadata":{"id":"LykZmORA5xgw","colab_type":"text"},"source":["#### <練習問題 6-11>\n","\n","<練習問題 6-7>で使用した「student-mat.csv」を使って、学校（`school`）と性別（`sex`）を軸にして、`G1`、`G2`、`G3`の平均点をそれぞれ求めてみましょう。"]},{"cell_type":"markdown","metadata":{"id":"Qgxkinhy5xgw","colab_type":"text"},"source":["#### <練習問題 6-12>\n","\n","<練習問題 6-7>で使用した「student-mat.csv」を使って、学校（`school`）と性別（`sex`）を軸にして、`G1`、`G2`、`G3`の最大値、最小値をまとめて算出してみましょう。"]},{"cell_type":"markdown","metadata":{"id":"BGdUyPCE5xgx","colab_type":"text"},"source":["***"]},{"cell_type":"markdown","metadata":{"id":"UGTlkmam5xgy","colab_type":"text"},"source":["## 6.3 欠損データと異常値の取り扱いの基礎\n","ゴール：欠損データと異常値に対する基本的な対処方法を知る"]},{"cell_type":"markdown","metadata":{"id":"zz-ZDzXw5xgy","colab_type":"text"},"source":["データを扱っていると必ずといっていいほど、欠損しているデータや異常値データの存在があります。この節では、基礎の基礎レベルで欠損データや異常データについての判定や扱い方について学ぶことにします。もっと深く学びたい方は、ぜひ参考文献「A-12」を読んでください。"]},{"cell_type":"markdown","metadata":{"id":"3gSH6sb-5xgz","colab_type":"text"},"source":["### 6.3.1 欠損データの扱い方\n","キーワード：リストワイズ削除、ペアワイズ削除、平均値代入法"]},{"cell_type":"markdown","metadata":{"id":"uteG8rSB5xgz","colab_type":"text"},"source":["まずは、欠損データの取り扱いについてです。データの欠損は、入力忘れ、無回答、システム上の問題などさまざまな要因があります。「ない」データについては、無視をするのがいいのか、除外をするのがいいのか、もっともらしい値を入れるのがいいのか、それが問題です。アプローチによっては、大きなバイアスのある結果を与え、誤った意思決定につながり、大きな損失につながる可能性もあります。慎重に扱っていきましょう。\n","\n","この節では、次のようなデータをサンプルとして扱います。値を`NaN`（`NA`）にした部分が欠損データであるとして、以下、説明を続けます。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"D5CnqLAx5xgz","colab_type":"code","colab":{}},"source":["# データの準備\n","import numpy as np\n","from numpy import nan as NA\n","import pandas as pd\n","\n","\n","df = pd.DataFrame(np.random.rand(10, 4))\n","\n","# NAにする\n","df.iloc[1,0] = NA\n","df.iloc[2:3,2] = NA\n","df.iloc[5:,3] = NA"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oP10R4fS5xg3","colab_type":"code","colab":{}},"source":["df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lKQPd6Ft5xg5","colab_type":"text"},"source":["以下では、この擬似的な欠損データに対して、削除や0や直前の数字、平均値等で穴埋めをしていきます。本書では、これらの単純な方法のみ紹介しますが、他の方法として、最尤推定法で推定したり、回帰代入やScipyで実施したスプライン補間などもあります。注意が必要なのは、これらの方法がバイアスを生む可能性があることです。ここで紹介する方法がベストであるとはいえません。深く学びたい方はぜひ参考文献「A-12」などを読んで、欠損データを埋める方法への理解を深めてください。"]},{"cell_type":"markdown","metadata":{"id":"m1UqHO-r5xg6","colab_type":"text"},"source":["#### リストワイズ削除\n","NaNがある行をすべて取り除くには、`dropna`メソッドを使います。これを**リストワイズ削除**といいます。\n","以下は、先ほどのデータにおいて、`dropna`メソッドを適用し、すべてのカラムにデータがある行だけを抽出したものです。`NaN`がある行は除外されます。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"QnTlIz0H5xg6","colab_type":"code","colab":{}},"source":["df.dropna()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oWOFWgUx5xg8","colab_type":"text"},"source":["#### ペアワイズ削除\n","この結果からわかるように、リストワイズ削除では元々10行あったデータが極端に少なくなって、データが全く使えないという状況が考えられます。このとき、欠損している列のデータを無視して、利用可能なデータのみ（例：列の0番目と1番目のみ存在）を使う方法があります。これを**ペアワイズ削除**といいます。ペアワイズ削除では、使いたい列を取り出してから`dropna`メソッドを適用します。"]},{"cell_type":"code","metadata":{"id":"2Nb56PsB5xg9","colab_type":"code","colab":{}},"source":["df[[0,1]].dropna()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"so56i8Ws5xg_","colab_type":"text"},"source":["#### fillnaで埋める\n","他の処理として、`fillna`（値）で、`NaN`になっている箇所をある値で埋める方法もあります。たとえば`NaN`を0として扱うケースです。次のように`fillna(0)`とすると、`NaN`が0に置き変わります。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"4aIKrmSW5xhA","colab_type":"code","colab":{}},"source":["df.fillna(0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qwlaGtaj5xhB","colab_type":"text"},"source":["#### 前の値で埋める\n","`ffill`メソッドを適用すると、直前の行の値で埋めることができます。具体的には、2行1列目（インデックス「1」/カラム「0」の値）は先ほど\n","\n","`df.iloc[1,0] = NA`\n","\n","で`NA`にしましたが、直前の1行1列目の値は、0.893145でしたので、この値で埋めることができます。この処理は金融の時系列データの処理などで使うことができ、便利です。"]},{"cell_type":"code","metadata":{"id":"sNRaBsMr5xhB","colab_type":"code","colab":{}},"source":["df.fillna(method = 'ffill')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9iiAck6h5xhE","colab_type":"text"},"source":["#### 平均値で埋める\n","他に、平均値で穴埋めする方法もあります。これを**平均値代入法**といい、`mean`メソッドを使います。なお、注意点として、時系列データを扱う際、この方法は未来情報を含むことがある（過去に欠損したデータを、未来のデータを使った平均値で埋める）ので、気を付けましょう。"]},{"cell_type":"code","metadata":{"id":"cb3hXweH5xhE","colab_type":"code","colab":{}},"source":["# 各カラムの平均値(確認用)\n","df.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aA_zLfiU5xhG","colab_type":"code","colab":{}},"source":["df.fillna(df.mean())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xrC6M5Te5xhI","colab_type":"text"},"source":["他にも色々とオプションがあるので、`?df.fillna`等で調べてみてください。\n","\n","欠損データについて、ここではサンプルデータにおいて、一定の値を機械的に置換しました。ただし、これらの方法はいつも使えるというわけではありません。データの状況、背景等を考え、適切に対処することが重要です。"]},{"cell_type":"markdown","metadata":{"id":"QclWJWA65xhJ","colab_type":"text"},"source":["#### <練習問題 6-13>\n","\n","以下のデータに対して、1列でも`NaN`がある場合は削除し、その結果を表示してください。"]},{"cell_type":"code","metadata":{"id":"Oc8Y1s0g5xhJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":514},"outputId":"d7378a94-1378-467e-84d0-482e1643a72e","executionInfo":{"status":"ok","timestamp":1579597498898,"user_tz":-540,"elapsed":1472,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["# データの準備\n","import numpy as np\n","from numpy import nan as NA\n","import pandas as pd\n","\n","\n","df2 = pd.DataFrame(np.random.rand(15,6))\n","\n","# NAにする\n","df2.iloc[2,0] = NA\n","df2.iloc[5:8,2] = NA\n","df2.iloc[7:9,3] = NA\n","df2.iloc[10,5] = NA\n","\n","\n","df2"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.426822</td>\n","      <td>0.864221</td>\n","      <td>0.285626</td>\n","      <td>0.164612</td>\n","      <td>0.691871</td>\n","      <td>0.511582</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.721420</td>\n","      <td>0.726100</td>\n","      <td>0.481214</td>\n","      <td>0.077604</td>\n","      <td>0.197607</td>\n","      <td>0.166913</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>0.069243</td>\n","      <td>0.687145</td>\n","      <td>0.119536</td>\n","      <td>0.955787</td>\n","      <td>0.792858</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.065585</td>\n","      <td>0.709469</td>\n","      <td>0.444288</td>\n","      <td>0.527154</td>\n","      <td>0.392572</td>\n","      <td>0.523901</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.212397</td>\n","      <td>0.965231</td>\n","      <td>0.138599</td>\n","      <td>0.625787</td>\n","      <td>0.806736</td>\n","      <td>0.095153</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.253069</td>\n","      <td>0.638784</td>\n","      <td>NaN</td>\n","      <td>0.192120</td>\n","      <td>0.854952</td>\n","      <td>0.229765</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.083640</td>\n","      <td>0.184024</td>\n","      <td>NaN</td>\n","      <td>0.371616</td>\n","      <td>0.444883</td>\n","      <td>0.082318</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.964525</td>\n","      <td>0.111553</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.597009</td>\n","      <td>0.096519</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.240281</td>\n","      <td>0.975854</td>\n","      <td>0.792412</td>\n","      <td>NaN</td>\n","      <td>0.316876</td>\n","      <td>0.233328</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.731141</td>\n","      <td>0.813273</td>\n","      <td>0.410351</td>\n","      <td>0.102311</td>\n","      <td>0.282168</td>\n","      <td>0.475242</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.493894</td>\n","      <td>0.960400</td>\n","      <td>0.397334</td>\n","      <td>0.577671</td>\n","      <td>0.160165</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.462023</td>\n","      <td>0.120670</td>\n","      <td>0.780847</td>\n","      <td>0.928250</td>\n","      <td>0.597966</td>\n","      <td>0.235548</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.976392</td>\n","      <td>0.669100</td>\n","      <td>0.099481</td>\n","      <td>0.064257</td>\n","      <td>0.616323</td>\n","      <td>0.154812</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.248990</td>\n","      <td>0.673377</td>\n","      <td>0.918378</td>\n","      <td>0.458906</td>\n","      <td>0.241035</td>\n","      <td>0.960064</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.837123</td>\n","      <td>0.046464</td>\n","      <td>0.906619</td>\n","      <td>0.234357</td>\n","      <td>0.299172</td>\n","      <td>0.997938</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           0         1         2         3         4         5\n","0   0.426822  0.864221  0.285626  0.164612  0.691871  0.511582\n","1   0.721420  0.726100  0.481214  0.077604  0.197607  0.166913\n","2        NaN  0.069243  0.687145  0.119536  0.955787  0.792858\n","3   0.065585  0.709469  0.444288  0.527154  0.392572  0.523901\n","4   0.212397  0.965231  0.138599  0.625787  0.806736  0.095153\n","5   0.253069  0.638784       NaN  0.192120  0.854952  0.229765\n","6   0.083640  0.184024       NaN  0.371616  0.444883  0.082318\n","7   0.964525  0.111553       NaN       NaN  0.597009  0.096519\n","8   0.240281  0.975854  0.792412       NaN  0.316876  0.233328\n","9   0.731141  0.813273  0.410351  0.102311  0.282168  0.475242\n","10  0.493894  0.960400  0.397334  0.577671  0.160165       NaN\n","11  0.462023  0.120670  0.780847  0.928250  0.597966  0.235548\n","12  0.976392  0.669100  0.099481  0.064257  0.616323  0.154812\n","13  0.248990  0.673377  0.918378  0.458906  0.241035  0.960064\n","14  0.837123  0.046464  0.906619  0.234357  0.299172  0.997938"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"VkQndvhtWR-l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":514},"outputId":"25d474a8-e012-4ebe-ac80-abadf716375b","executionInfo":{"status":"ok","timestamp":1579597607050,"user_tz":-540,"elapsed":967,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["df2.dropna(axis=1)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.864221</td>\n","      <td>0.691871</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.726100</td>\n","      <td>0.197607</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.069243</td>\n","      <td>0.955787</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.709469</td>\n","      <td>0.392572</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.965231</td>\n","      <td>0.806736</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.638784</td>\n","      <td>0.854952</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.184024</td>\n","      <td>0.444883</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.111553</td>\n","      <td>0.597009</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.975854</td>\n","      <td>0.316876</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.813273</td>\n","      <td>0.282168</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.960400</td>\n","      <td>0.160165</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.120670</td>\n","      <td>0.597966</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.669100</td>\n","      <td>0.616323</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.673377</td>\n","      <td>0.241035</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.046464</td>\n","      <td>0.299172</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           1         4\n","0   0.864221  0.691871\n","1   0.726100  0.197607\n","2   0.069243  0.955787\n","3   0.709469  0.392572\n","4   0.965231  0.806736\n","5   0.638784  0.854952\n","6   0.184024  0.444883\n","7   0.111553  0.597009\n","8   0.975854  0.316876\n","9   0.813273  0.282168\n","10  0.960400  0.160165\n","11  0.120670  0.597966\n","12  0.669100  0.616323\n","13  0.673377  0.241035\n","14  0.046464  0.299172"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"BTkSuWvY5xhL","colab_type":"text"},"source":["#### <練習問題 6-14>\n","\n","<練習問題 6-13>で準備したデータに対して、`NaN`を0で埋めてください。"]},{"cell_type":"code","metadata":{"id":"aGRESbPoWRVy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":514},"outputId":"6e39198e-7edd-4dfa-b751-19d8a63366e0","executionInfo":{"status":"ok","timestamp":1579597632861,"user_tz":-540,"elapsed":636,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["df2.fillna(0)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.426822</td>\n","      <td>0.864221</td>\n","      <td>0.285626</td>\n","      <td>0.164612</td>\n","      <td>0.691871</td>\n","      <td>0.511582</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.721420</td>\n","      <td>0.726100</td>\n","      <td>0.481214</td>\n","      <td>0.077604</td>\n","      <td>0.197607</td>\n","      <td>0.166913</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.069243</td>\n","      <td>0.687145</td>\n","      <td>0.119536</td>\n","      <td>0.955787</td>\n","      <td>0.792858</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.065585</td>\n","      <td>0.709469</td>\n","      <td>0.444288</td>\n","      <td>0.527154</td>\n","      <td>0.392572</td>\n","      <td>0.523901</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.212397</td>\n","      <td>0.965231</td>\n","      <td>0.138599</td>\n","      <td>0.625787</td>\n","      <td>0.806736</td>\n","      <td>0.095153</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.253069</td>\n","      <td>0.638784</td>\n","      <td>0.000000</td>\n","      <td>0.192120</td>\n","      <td>0.854952</td>\n","      <td>0.229765</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.083640</td>\n","      <td>0.184024</td>\n","      <td>0.000000</td>\n","      <td>0.371616</td>\n","      <td>0.444883</td>\n","      <td>0.082318</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.964525</td>\n","      <td>0.111553</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.597009</td>\n","      <td>0.096519</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.240281</td>\n","      <td>0.975854</td>\n","      <td>0.792412</td>\n","      <td>0.000000</td>\n","      <td>0.316876</td>\n","      <td>0.233328</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.731141</td>\n","      <td>0.813273</td>\n","      <td>0.410351</td>\n","      <td>0.102311</td>\n","      <td>0.282168</td>\n","      <td>0.475242</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.493894</td>\n","      <td>0.960400</td>\n","      <td>0.397334</td>\n","      <td>0.577671</td>\n","      <td>0.160165</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.462023</td>\n","      <td>0.120670</td>\n","      <td>0.780847</td>\n","      <td>0.928250</td>\n","      <td>0.597966</td>\n","      <td>0.235548</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.976392</td>\n","      <td>0.669100</td>\n","      <td>0.099481</td>\n","      <td>0.064257</td>\n","      <td>0.616323</td>\n","      <td>0.154812</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.248990</td>\n","      <td>0.673377</td>\n","      <td>0.918378</td>\n","      <td>0.458906</td>\n","      <td>0.241035</td>\n","      <td>0.960064</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.837123</td>\n","      <td>0.046464</td>\n","      <td>0.906619</td>\n","      <td>0.234357</td>\n","      <td>0.299172</td>\n","      <td>0.997938</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           0         1         2         3         4         5\n","0   0.426822  0.864221  0.285626  0.164612  0.691871  0.511582\n","1   0.721420  0.726100  0.481214  0.077604  0.197607  0.166913\n","2   0.000000  0.069243  0.687145  0.119536  0.955787  0.792858\n","3   0.065585  0.709469  0.444288  0.527154  0.392572  0.523901\n","4   0.212397  0.965231  0.138599  0.625787  0.806736  0.095153\n","5   0.253069  0.638784  0.000000  0.192120  0.854952  0.229765\n","6   0.083640  0.184024  0.000000  0.371616  0.444883  0.082318\n","7   0.964525  0.111553  0.000000  0.000000  0.597009  0.096519\n","8   0.240281  0.975854  0.792412  0.000000  0.316876  0.233328\n","9   0.731141  0.813273  0.410351  0.102311  0.282168  0.475242\n","10  0.493894  0.960400  0.397334  0.577671  0.160165  0.000000\n","11  0.462023  0.120670  0.780847  0.928250  0.597966  0.235548\n","12  0.976392  0.669100  0.099481  0.064257  0.616323  0.154812\n","13  0.248990  0.673377  0.918378  0.458906  0.241035  0.960064\n","14  0.837123  0.046464  0.906619  0.234357  0.299172  0.997938"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"XMBYV-8M5xhL","colab_type":"text"},"source":["#### <練習問題 6-15>\n","\n","<練習問題 6-13>で準備したデータに対して、`NaN`をそれぞれの列の平均値で埋めてください。"]},{"cell_type":"code","metadata":{"id":"3jmAaUoIWzuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":514},"outputId":"28ae9223-7fa0-4641-aa97-f66aa4a6acd6","executionInfo":{"status":"ok","timestamp":1579597672406,"user_tz":-540,"elapsed":645,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["df2.fillna(df2.mean())"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.426822</td>\n","      <td>0.864221</td>\n","      <td>0.285626</td>\n","      <td>0.164612</td>\n","      <td>0.691871</td>\n","      <td>0.511582</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.721420</td>\n","      <td>0.726100</td>\n","      <td>0.481214</td>\n","      <td>0.077604</td>\n","      <td>0.197607</td>\n","      <td>0.166913</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.479807</td>\n","      <td>0.069243</td>\n","      <td>0.687145</td>\n","      <td>0.119536</td>\n","      <td>0.955787</td>\n","      <td>0.792858</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.065585</td>\n","      <td>0.709469</td>\n","      <td>0.444288</td>\n","      <td>0.527154</td>\n","      <td>0.392572</td>\n","      <td>0.523901</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.212397</td>\n","      <td>0.965231</td>\n","      <td>0.138599</td>\n","      <td>0.625787</td>\n","      <td>0.806736</td>\n","      <td>0.095153</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.253069</td>\n","      <td>0.638784</td>\n","      <td>0.528525</td>\n","      <td>0.192120</td>\n","      <td>0.854952</td>\n","      <td>0.229765</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.083640</td>\n","      <td>0.184024</td>\n","      <td>0.528525</td>\n","      <td>0.371616</td>\n","      <td>0.444883</td>\n","      <td>0.082318</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.964525</td>\n","      <td>0.111553</td>\n","      <td>0.528525</td>\n","      <td>0.341860</td>\n","      <td>0.597009</td>\n","      <td>0.096519</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.240281</td>\n","      <td>0.975854</td>\n","      <td>0.792412</td>\n","      <td>0.341860</td>\n","      <td>0.316876</td>\n","      <td>0.233328</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.731141</td>\n","      <td>0.813273</td>\n","      <td>0.410351</td>\n","      <td>0.102311</td>\n","      <td>0.282168</td>\n","      <td>0.475242</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.493894</td>\n","      <td>0.960400</td>\n","      <td>0.397334</td>\n","      <td>0.577671</td>\n","      <td>0.160165</td>\n","      <td>0.396853</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.462023</td>\n","      <td>0.120670</td>\n","      <td>0.780847</td>\n","      <td>0.928250</td>\n","      <td>0.597966</td>\n","      <td>0.235548</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.976392</td>\n","      <td>0.669100</td>\n","      <td>0.099481</td>\n","      <td>0.064257</td>\n","      <td>0.616323</td>\n","      <td>0.154812</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.248990</td>\n","      <td>0.673377</td>\n","      <td>0.918378</td>\n","      <td>0.458906</td>\n","      <td>0.241035</td>\n","      <td>0.960064</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.837123</td>\n","      <td>0.046464</td>\n","      <td>0.906619</td>\n","      <td>0.234357</td>\n","      <td>0.299172</td>\n","      <td>0.997938</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           0         1         2         3         4         5\n","0   0.426822  0.864221  0.285626  0.164612  0.691871  0.511582\n","1   0.721420  0.726100  0.481214  0.077604  0.197607  0.166913\n","2   0.479807  0.069243  0.687145  0.119536  0.955787  0.792858\n","3   0.065585  0.709469  0.444288  0.527154  0.392572  0.523901\n","4   0.212397  0.965231  0.138599  0.625787  0.806736  0.095153\n","5   0.253069  0.638784  0.528525  0.192120  0.854952  0.229765\n","6   0.083640  0.184024  0.528525  0.371616  0.444883  0.082318\n","7   0.964525  0.111553  0.528525  0.341860  0.597009  0.096519\n","8   0.240281  0.975854  0.792412  0.341860  0.316876  0.233328\n","9   0.731141  0.813273  0.410351  0.102311  0.282168  0.475242\n","10  0.493894  0.960400  0.397334  0.577671  0.160165  0.396853\n","11  0.462023  0.120670  0.780847  0.928250  0.597966  0.235548\n","12  0.976392  0.669100  0.099481  0.064257  0.616323  0.154812\n","13  0.248990  0.673377  0.918378  0.458906  0.241035  0.960064\n","14  0.837123  0.046464  0.906619  0.234357  0.299172  0.997938"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"2zSnw-RF5xhL","colab_type":"text"},"source":["### 6.3.2 異常データの扱い方\n","キーワード：異常値、箱ひげ図、パーセンタイル、VaR（Value At Risk）"]},{"cell_type":"markdown","metadata":{"id":"AL78NtnN5xhM","colab_type":"text"},"source":["次は、異常値（外れ値）についてです。異常値データの扱いは、そのままにして何もしないのか、異常値を除去するか、もっともらしい値に入れかえて使うかが問題になります。\n","そもそも異常値とは一体何でしょうか。実は、統一的な見解というものはなく、そのデータを扱うアナリストや意思決定者が判断することもあります。ビジネスの現場では、不正アクセスのパターン（セキュリティ分野）や機械の故障、金融リスク管理（VaR）など、さまざまな分野で使われており、それぞれ色々な方法でアプローチされています。"]},{"cell_type":"markdown","metadata":{"id":"8sk7p7935xhN","colab_type":"text"},"source":["異常値検出のアプローチには、単純に箱ひげ図などを書いて、あるパーセンタイル以上のデータを異常値としてみなす方法、正規分布を利用する方法、データの空間的な近さに基づく方法などがあります。他には以降の章で学ぶ機械学習（教師なし学習も含む）を用いた方法もあります。\n","\n","ここでは特に練習問題はありませんが、興味のある方はぜひ巻末の参考文献「A-13」や参考URL「B-22」などで学んでください。"]},{"cell_type":"markdown","metadata":{"id":"4esGzwIU5xhO","colab_type":"text"},"source":["また、異常値の分野に関連して、極端な値を研究する極値統計学という分野もあります。データの中で大きな値をとる極値データの挙動について、さまざまな研究がなされており、稀ではありますがそれが起きれば非常に大きな影響を及ぼす現象（自然現象、災害など）を研究します。気象学だけではなく、ファイナンスや情報通信の分野でも応用されているので、興味のある方は参考文献「A-14」などを参照してみてください。"]},{"cell_type":"markdown","metadata":{"id":"WwlL54JO5xhO","colab_type":"text"},"source":["以上で、欠損値と異常値の扱いについてはこれで終わりになります。データ分析において、データの前処理が8割だとよく言われ、欠損データや異常値データには、たびたび遭遇します。また、世の中には実にさまざまな形式のデータが存在し、それらを整えるだけでも大変な作業です。ここで紹介したテクニックも重要ですが、それらに対してどのように対処していくのか戦略を立てることも重要です。参考文献「A-15」にも、ぜひ目を通してみてください。"]},{"cell_type":"markdown","metadata":{"id":"Fc1Z6XQ85xhO","colab_type":"text"},"source":["***"]},{"cell_type":"markdown","metadata":{"id":"alQDZzht5xhP","colab_type":"text"},"source":["## 6.4 時系列データの取り扱いの基礎\n","ゴール：Pandasを使って、時系列データの基本的な扱い方を身に付ける"]},{"cell_type":"markdown","metadata":{"id":"5oyY1r_s5xhT","colab_type":"text"},"source":["最後にPandasを使った時系列データの取り扱いについて学びます。ここでは、サンプルとして為替の時系列データを扱います。\n","あらかじめAppendixを参考に`pandas-datareader`というライブラリをダウンロードしてインストールしてから進めてください。"]},{"cell_type":"markdown","metadata":{"id":"NYcHlx125xhT","colab_type":"text"},"source":["インストールしたら、次のようにインポートしてください。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"W3Paasac5xhU","colab_type":"code","colab":{}},"source":["import pandas_datareader.data as pdr"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xppSbKhl5xhW","colab_type":"text"},"source":["### 6.4.1 時系列データの処理と変換\n","キーワード：リサンプリング、シフト"]},{"cell_type":"markdown","metadata":{"id":"f-e-2oiy5xhX","colab_type":"text"},"source":["ここでは、サンプルデータに含まれる2001/1/2から2016/12/30までのドル円の為替レートデータ（DEXJPUS）を使います。日ごとのレートデータで、欠損している日（休日など）もあります。"]},{"cell_type":"code","metadata":{"id":"8btJbvb95xhX","colab_type":"code","colab":{}},"source":["!pip install pandas-datareader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNZQaDBm5xha","colab_type":"code","colab":{}},"source":["start_date = '2001/1/2'\n","end_date = '2016/12/30'\n","\n","fx_jpusdata = pdr.DataReader('DEXJPUS', 'fred', start_date, end_date) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XAKlQ9PJ5xhb","colab_type":"text"},"source":["`head`メソッドを使って、読み込んだfx_jpusdataの先頭5行を読み出します。"]},{"cell_type":"code","metadata":{"id":"tEW7LNh_5xhc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"c4ce1ecf-145f-4132-e890-d47ecd5ce142","executionInfo":{"status":"ok","timestamp":1579598214592,"user_tz":-540,"elapsed":399,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["fx_jpusdata.isnull().sum()"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DEXJPUS    154\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"yS33titE5xhe","colab_type":"text"},"source":["サンプルには、15年分のデータがありますが、これをどう分析するかはそのビジネスニーズ次第です。たとえば、最後の2016年の4月のデータだけ欲しいこともありますし、月末のレートだけを見たいこともあります。さらに、上記では、2001/1/6はデータとしてありませんが、それを前日の値で埋めたいこともありますし、前の日と比べてどれだけレートが上がったのか調べたい場合もあるでしょう。これらのことはすべてPandasで簡単に計算することができます。\n","\n","#### 特定の年月のデータを参照する\n","\n","まずは、特定の年月のデータを参照する方法です。2016年の4月のデータだけ見たい場合は、以下のように年月を指定します。"]},{"cell_type":"code","metadata":{"id":"EnAaZ1Ft5xhe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":731},"outputId":"2ec479aa-6b18-42b5-c72f-4041de2df742","executionInfo":{"status":"ok","timestamp":1579598377386,"user_tz":-540,"elapsed":1272,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["fx_jpusdata['2016-04']"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DEXJPUS</th>\n","    </tr>\n","    <tr>\n","      <th>DATE</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2016-04-01</th>\n","      <td>112.06</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-04</th>\n","      <td>111.18</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-05</th>\n","      <td>110.26</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-06</th>\n","      <td>109.63</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-07</th>\n","      <td>107.98</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-08</th>\n","      <td>108.36</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-11</th>\n","      <td>107.96</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-12</th>\n","      <td>108.54</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-13</th>\n","      <td>109.21</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-14</th>\n","      <td>109.20</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-15</th>\n","      <td>108.76</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-18</th>\n","      <td>108.85</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-19</th>\n","      <td>109.16</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-20</th>\n","      <td>109.51</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-21</th>\n","      <td>109.41</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-22</th>\n","      <td>111.50</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-25</th>\n","      <td>111.08</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-26</th>\n","      <td>111.23</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-27</th>\n","      <td>111.26</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-28</th>\n","      <td>108.55</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-29</th>\n","      <td>106.90</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            DEXJPUS\n","DATE               \n","2016-04-01   112.06\n","2016-04-04   111.18\n","2016-04-05   110.26\n","2016-04-06   109.63\n","2016-04-07   107.98\n","2016-04-08   108.36\n","2016-04-11   107.96\n","2016-04-12   108.54\n","2016-04-13   109.21\n","2016-04-14   109.20\n","2016-04-15   108.76\n","2016-04-18   108.85\n","2016-04-19   109.16\n","2016-04-20   109.51\n","2016-04-21   109.41\n","2016-04-22   111.50\n","2016-04-25   111.08\n","2016-04-26   111.23\n","2016-04-27   111.26\n","2016-04-28   108.55\n","2016-04-29   106.90"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"lwpi76275xhf","colab_type":"text"},"source":["そのほか、特定の年や日にちにだけ抽出することもできます。\n","次に、月末レートだけ取り出してみましょう。`resample`メソッドの引数に`M`を指定することで、月ごとのデータを取り出し、`last`メソッドで末尾のデータを取り出しています。具体的には、以下の結果をみるとわかる通り、1月、2月、3月…の月末のレートを取り出せます。"]},{"cell_type":"code","metadata":{"id":"Bfso7YBS5xhf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"1acabfd1-280f-4109-c888-3645b6cfc0fc","executionInfo":{"status":"ok","timestamp":1579598377858,"user_tz":-540,"elapsed":704,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["fx_jpusdata.resample('M').last().head()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DEXJPUS</th>\n","    </tr>\n","    <tr>\n","      <th>DATE</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2001-01-31</th>\n","      <td>116.39</td>\n","    </tr>\n","    <tr>\n","      <th>2001-02-28</th>\n","      <td>117.28</td>\n","    </tr>\n","    <tr>\n","      <th>2001-03-31</th>\n","      <td>125.54</td>\n","    </tr>\n","    <tr>\n","      <th>2001-04-30</th>\n","      <td>123.57</td>\n","    </tr>\n","    <tr>\n","      <th>2001-05-31</th>\n","      <td>118.88</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            DEXJPUS\n","DATE               \n","2001-01-31   116.39\n","2001-02-28   117.28\n","2001-03-31   125.54\n","2001-04-30   123.57\n","2001-05-31   118.88"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"7is2JOTG5xhg","colab_type":"text"},"source":["日付を取り出したい場合は「`D`」、年を取り出したい場合は「`Y`」を、それぞれ引数に指定します。このように、ある頻度のデータを、別の頻度のデータで取り出し直す処理を**リサンプリング**といいます。また、最後のデータではなく、その平均を計算したい場合は`mean`メソッドを使うことで計算できます。他にもいろいろとパラメータを設定できるので、必要な処理があるときに、調べてみてください。"]},{"cell_type":"markdown","metadata":{"id":"emHSSjLv5xhg","colab_type":"text"},"source":["#### 欠損がある場合の操作\n","\n","次に、時系列データに欠損がある場合の処理をみていきます。欠損処理については、前の節でも扱った通り、さまざまな方法があります。先ほどのレートでは、2001/1/6がまずレコードとして存在していませんでしたが、日ごとにデータを用意したいときは、先ほどのリサンプリングを行います。具体的には、以下のようにします。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"3mo0k2bZ5xhh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"7af389d4-3c53-4a05-c317-99d37be4fbc2","executionInfo":{"status":"ok","timestamp":1579598380355,"user_tz":-540,"elapsed":688,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["fx_jpusdata.resample('D').last().head()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DEXJPUS</th>\n","    </tr>\n","    <tr>\n","      <th>DATE</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2001-01-02</th>\n","      <td>114.73</td>\n","    </tr>\n","    <tr>\n","      <th>2001-01-03</th>\n","      <td>114.26</td>\n","    </tr>\n","    <tr>\n","      <th>2001-01-04</th>\n","      <td>115.47</td>\n","    </tr>\n","    <tr>\n","      <th>2001-01-05</th>\n","      <td>116.19</td>\n","    </tr>\n","    <tr>\n","      <th>2001-01-06</th>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            DEXJPUS\n","DATE               \n","2001-01-02   114.73\n","2001-01-03   114.26\n","2001-01-04   115.47\n","2001-01-05   116.19\n","2001-01-06      NaN"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"Drb0WGuY5xhk","colab_type":"text"},"source":["上記より、2001/1/6は空のままなので、前の日の値で埋める処理をします。ここでは、次に示すようにffillメソッドを使います。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ej_zJYgI5xhk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"1a4cd424-cd1f-4405-8074-b21d3485b49e","executionInfo":{"status":"ok","timestamp":1579598383017,"user_tz":-540,"elapsed":728,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["fx_jpusdata.resample('D').ffill().head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DEXJPUS</th>\n","    </tr>\n","    <tr>\n","      <th>DATE</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2001-01-02</th>\n","      <td>114.73</td>\n","    </tr>\n","    <tr>\n","      <th>2001-01-03</th>\n","      <td>114.26</td>\n","    </tr>\n","    <tr>\n","      <th>2001-01-04</th>\n","      <td>115.47</td>\n","    </tr>\n","    <tr>\n","      <th>2001-01-05</th>\n","      <td>116.19</td>\n","    </tr>\n","    <tr>\n","      <th>2001-01-06</th>\n","      <td>116.19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            DEXJPUS\n","DATE               \n","2001-01-02   114.73\n","2001-01-03   114.26\n","2001-01-04   115.47\n","2001-01-05   116.19\n","2001-01-06   116.19"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"bQhm1nDj5xhl","colab_type":"text"},"source":["#### データをズラして比率を計算する\n","\n","次に、前日とのレート比較をしたい場合を考えます。上のデータ例でいうと、2001-01-02のレートは114.73で、2001-01-03のレートは114.26になり、その比率を計算することもできますが、それをすべての日付について適応させる処理をします。shiftメソッドを使うことで、インデックスは固定したまま、そのデータだけをずらすことができます。以下はデータを1つあとにずらしており、2001-01-02のレートは114.73でしたが、2001-01-03のレートとして扱われるようになります。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ibW7oKm25xhm","colab_type":"code","colab":{}},"source":["fx_jpusdata.shift(1).head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4VGrcFJ85xho","colab_type":"text"},"source":["このように加工すると、前日のレートと当日のレートの比率を一気に算出することができます。これがPandasを使うメリットです。なお、以下で2001-01-02が`NaN`になっているのは、その前日のデータがもともとないためです。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"GeTH19vE5xho","colab_type":"code","colab":{}},"source":["fx_jpusdata_ratio = fx_jpusdata / fx_jpusdata.shift(1)\n","fx_jpusdata_ratio.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eJwdvWcX5xhr","colab_type":"text"},"source":["なお、差分や比率を取る方法については、`diff`や`pct_change`などもありますので、興味がある方は調べてみてください。"]},{"cell_type":"markdown","metadata":{"id":"ctTA3tdh5xhr","colab_type":"text"},"source":[">**[やってみよう]**\n",">\n",">`diff`や`pct_change`について、それらの機能を調べて、使ってみましょう。"]},{"cell_type":"markdown","metadata":{"id":"BEyYBB845xhr","colab_type":"text"},"source":["#### <練習問題 6-16>\n","\n","上記のようにして読み込んだ\n","を使って、年ごとの平均値の推移データを作成してください。"]},{"cell_type":"code","metadata":{"id":"2rnvwAK0Zpxt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"outputId":"956a68fa-4857-488a-dfdf-1e2832a9df50","executionInfo":{"status":"ok","timestamp":1579598542313,"user_tz":-540,"elapsed":1090,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","data = fx_jpusdata.resample('Y').mean()\n","plt.plot( data )\n","plt.grid(True)"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"ZEl_wDQ35xhs","colab_type":"text"},"source":["### 6.4.2 移動平均\n","キーワード：移動平均"]},{"cell_type":"markdown","metadata":{"id":"dE656PzZ5xhs","colab_type":"text"},"source":["次に、時系列のデータ処理でよく使われる移動平均の処理方法をみていきます。さきほど扱った`fx_jpusdata`のデータについて、3日間の移動平均線を作成することを考えます。まず先頭から5行のデータを取り出してみます。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"812Zzgdq5xhs","colab_type":"code","colab":{}},"source":["fx_jpusdata.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GLBg0uSG5xht","colab_type":"text"},"source":["結果を見るとわかるように、2001-01-04までのデータは、2001-01-02が114.73、2001-01-03が114.26、2001-01-04が115.47ですから、その平均を計算すると114.82です。同様にして、2001-01-05、2001-01-06と続けて計算をしていきます。それにはPpandasの`rolling`メソッドを使うと、簡単に計算できます。以下は、その3日間の移動平均を計算した結果です。`rolling`メソッドを実行した後に、`mean`メソッドを使って平均を計算しています。"]},{"cell_type":"code","metadata":{"id":"ueKW7Fe-5xhu","colab_type":"code","colab":{}},"source":["fx_jpusdata.rolling(3).mean().head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wRLMFkha5xhv","colab_type":"text"},"source":["移動平均ではなく標準偏差の推移を算出したいのなら、`mean`メソッドの代わりに`std`メソッドを使います。以下は3日間の標準偏差の推移です。"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"dTA42rY95xhv","colab_type":"code","colab":{}},"source":["fx_jpusdata.rolling(3).std().head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YMP9AgcC5xhw","colab_type":"text"},"source":["`rolling`メソッドには、パラメータが他にもいろいろとありますので、必要に応じて調べて実行してみてください。"]},{"cell_type":"markdown","metadata":{"id":"C0rZfN7a5xhw","colab_type":"text"},"source":["以上で、Pandasの章は終了です。一部、なかなかイメージを掴みにくい箇所もあったかもしれません。しかし、実際に「こんな感じでデータ加工や変換したいのになあ」と思ったときに、ここを参考にしてプログラミングをしてみてください。データ加工処理のニーズが出てきて、実際に使うことで一層理解が進む箇所かもしれません。ここで紹介したテクニックはほんの一部です。この他にも、さまざまなデータ処理・加工方法があるので、参考文献「A-10」などを読んで、手を動かして実行してみてください。"]},{"cell_type":"markdown","metadata":{"id":"92IZ_aXK5xhx","colab_type":"text"},"source":[">**[やってみよう]**\n",">\n",">ここで扱った集計軸以外にも、対象データに対していろいろな軸で処理をしてみましょう。"]},{"cell_type":"markdown","metadata":{"id":"sFJxjCmI5xhx","colab_type":"text"},"source":["#### <練習問題 6-17>\n","\n","<練習問題 6-16>で使用したfx_jpusdataを使って、20日間の移動平均データを作成してください。ただし`NaN`は削除してください。なお、レコードとして存在しないデータであれば、特に補填する必要はありません。"]},{"cell_type":"code","metadata":{"id":"bj2gee-yagyg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":450},"outputId":"0d6dd8f1-1104-472e-ccf8-395ef3467e4d","executionInfo":{"status":"ok","timestamp":1579598680047,"user_tz":-540,"elapsed":584,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["# fx_jpusdata.dropna().rolling(20).mean().dropna()\n","fx_jpusdata.rolling(20).mean().dropna()"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DEXJPUS</th>\n","    </tr>\n","    <tr>\n","      <th>DATE</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2001-02-12</th>\n","      <td>116.6910</td>\n","    </tr>\n","    <tr>\n","      <th>2001-02-13</th>\n","      <td>116.6920</td>\n","    </tr>\n","    <tr>\n","      <th>2001-02-14</th>\n","      <td>116.6070</td>\n","    </tr>\n","    <tr>\n","      <th>2001-02-15</th>\n","      <td>116.5015</td>\n","    </tr>\n","    <tr>\n","      <th>2001-02-16</th>\n","      <td>116.4130</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2016-11-08</th>\n","      <td>104.1600</td>\n","    </tr>\n","    <tr>\n","      <th>2016-11-09</th>\n","      <td>104.1780</td>\n","    </tr>\n","    <tr>\n","      <th>2016-11-10</th>\n","      <td>104.3250</td>\n","    </tr>\n","    <tr>\n","      <th>2016-12-22</th>\n","      <td>115.1555</td>\n","    </tr>\n","    <tr>\n","      <th>2016-12-23</th>\n","      <td>115.3580</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1593 rows × 1 columns</p>\n","</div>"],"text/plain":["             DEXJPUS\n","DATE                \n","2001-02-12  116.6910\n","2001-02-13  116.6920\n","2001-02-14  116.6070\n","2001-02-15  116.5015\n","2001-02-16  116.4130\n","...              ...\n","2016-11-08  104.1600\n","2016-11-09  104.1780\n","2016-11-10  104.3250\n","2016-12-22  115.1555\n","2016-12-23  115.3580\n","\n","[1593 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"5ikqWvjX5xhx","colab_type":"text"},"source":["***"]},{"cell_type":"markdown","metadata":{"id":"wN8qYqYe5xhx","colab_type":"text"},"source":["## 6.5 総合問題"]},{"cell_type":"code","metadata":{"id":"unZf7E7ha46i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"b780389c-777c-40e7-82b8-dfb7bbf3c802","executionInfo":{"status":"ok","timestamp":1579598738498,"user_tz":-540,"elapsed":20800,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MxvUPjJQ5xhy","colab_type":"text"},"source":["### ■総合問題6-1 データ操作\n","\n","3章で使用した、数学の成績を示すデータである「student-mat.csv」を使って、以下の問いに答えてください。\n","\n","(1) 上記のデータに対して、年齢（`age`）×性別（`sex`）で`G1`の平均点を算出し、縦軸が年齢（`age`）、横軸が性別（`sex`）となるような表（テーブル）を作成しましょう。\n","\n","(2) (1)で表示した結果テーブルについて、NaNになっている行（レコード）をすべて削除した結果を表示しましょう。"]},{"cell_type":"code","metadata":{"id":"brvBZYtVbAPI","colab_type":"code","colab":{}},"source":["math_data = pd.read_csv('/content/drive/My Drive/DataScience/ds_samplefiles/student-mat.csv', sep=';')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYY0w1_dbJ3A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":328},"outputId":"a7153a35-31eb-4144-e702-59d30370b466","executionInfo":{"status":"ok","timestamp":1579598958312,"user_tz":-540,"elapsed":614,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["table = pd.pivot_table( math_data, index='age', columns='sex', values='G1')\n","table"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>sex</th>\n","      <th>F</th>\n","      <th>M</th>\n","    </tr>\n","    <tr>\n","      <th>age</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15</th>\n","      <td>10.052632</td>\n","      <td>12.250000</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>10.203704</td>\n","      <td>11.740000</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>11.103448</td>\n","      <td>10.600000</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>10.883721</td>\n","      <td>10.538462</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>10.642857</td>\n","      <td>9.700000</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>15.000000</td>\n","      <td>13.000000</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>NaN</td>\n","      <td>10.000000</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>NaN</td>\n","      <td>6.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["sex          F          M\n","age                      \n","15   10.052632  12.250000\n","16   10.203704  11.740000\n","17   11.103448  10.600000\n","18   10.883721  10.538462\n","19   10.642857   9.700000\n","20   15.000000  13.000000\n","21         NaN  10.000000\n","22         NaN   6.000000"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"AYi6TC8obstN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":266},"outputId":"52ac6fe9-09ee-4a69-91ab-0c011cb9639f","executionInfo":{"status":"ok","timestamp":1579598990549,"user_tz":-540,"elapsed":421,"user":{"displayName":"吉原千尋","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDACaAmK7hOpF5QNRTNQKWtrfY_TTAGafzc_IZYrg=s64","userId":"14873717983935456467"}}},"source":["table.dropna()"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>sex</th>\n","      <th>F</th>\n","      <th>M</th>\n","    </tr>\n","    <tr>\n","      <th>age</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15</th>\n","      <td>10.052632</td>\n","      <td>12.250000</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>10.203704</td>\n","      <td>11.740000</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>11.103448</td>\n","      <td>10.600000</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>10.883721</td>\n","      <td>10.538462</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>10.642857</td>\n","      <td>9.700000</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>15.000000</td>\n","      <td>13.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["sex          F          M\n","age                      \n","15   10.052632  12.250000\n","16   10.203704  11.740000\n","17   11.103448  10.600000\n","18   10.883721  10.538462\n","19   10.642857   9.700000\n","20   15.000000  13.000000"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"oYVHq3gBb8kk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}